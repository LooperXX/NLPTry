# Text Matching Based on Attention Mechanism

Based on [Pytorch](https://github.com/pytorch/pytorch) and TorchText
- [Word Emebedding](https://nlp.stanford.edu/projects/glove/) 

## Concepts


## Paper

- [Reasoning about Entailment with Neural Attention](https://arxiv.org/abs/1509.06664)  

- [Enhanced LSTM for Natural Language Inference](https://arxiv.org/abs/1609.06038v3)
    - 摘要: 与之前使用非常复杂的网络体系结构的顶级模型不同，我们首先证明了基于链LSTMs的顺序推理模型的精心设计可以优于所有之前的模型。在此基础上，我们进一步表明，通过在局部推理建模和推理组合中显式地考虑递归体系结构，我们实现了额外的改进。特别是，合并语法解析信息有助于获得最佳结果—即使添加到已经非常强大的模型中，它也会进一步提高性能。

## Reference
