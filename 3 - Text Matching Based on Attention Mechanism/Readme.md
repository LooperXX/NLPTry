# Text Matching Based on Attention Mechanism

Based on [Pytorch](https://github.com/pytorch/pytorch) and [TorchText](https://github.com/pytorch/text)
- [Dataset](https://nlp.stanford.edu/projects/snli/) `SNLI` 
    > The SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE). We aim for it to serve both as a benchmark for evaluating representational systems for text, especially including those induced by representation learning methods, as well as a resource for developing NLP models of any kind.
- [Word Emebedding](https://nlp.stanford.edu/projects/glove/) 

## Paper

- [Reasoning about Entailment with Neural Attention](https://arxiv.org/abs/1509.06664v1)  
- [Enhanced LSTM for Natural Language Inference](https://arxiv.org/abs/1609.06038v3)

## Reference

- https://blog.csdn.net/xiayto/article/details/81247461

## Others

s better for debug and `.ipynb` has better interactions- every model has `.ipynb` and `.py ` because `.py` i