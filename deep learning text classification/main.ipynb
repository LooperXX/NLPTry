{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "import re\nimport os\nimport numpy as np\nimport pandas as pd\nfrom torchtext import data\nfrom torchtext.vocab import Vectors\nfrom torchtext.data import Field, Iterator, BucketIterator, TabularDataset\nimport torch as t\nfrom torch.nn import init\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils import data\nfrom tqdm import tqdm\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nstopwords_english \u003d stopwords.words(\u0027english\u0027)\nlemmatizer \u003d WordNetLemmatizer()\n# max_len \u003d 0\n# for i in train.examples:\n#     max_len \u003d max(max_len, len(vars(i)[\u0027Text\u0027]))\n# for i in val.examples:\n#     max_len \u003d max(max_len, len(vars(i)[\u0027Text\u0027]))\n# for i in test.examples:\n#     max_len \u003d max(max_len, len(vars(i)[\u0027Text\u0027]))\n# max_len"
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "outputs": [],
      "source": "data_path \u003d \u0027E:\\\\workspace\\\\python-workspace\\\\NLPTry\\\\deep learning text classification\\\\\u0027\nvocab_path \u003d \u0027E:\\\\workspace\\\\jupyter_notebook\\\\.vector_cache\\\\\u0027\nclasses \u003d 5\nmax_len \u003d 56\nnum_filters \u003d 100\nkernel_sizes \u003d [3, 4, 5]\nlr\u003d0.001\nbatch_size\u003d32\nepochs \u003d 10\nprint_every \u003d 100\ndevice \u003d t.device(\u0027cuda:0\u0027)\nuse_gpu \u003d True",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "outputs": [],
      "source": "def tokenize_en(text):\n    words \u003d word_tokenize(text)\n    return [lemmatizer.lemmatize(i) for i in words]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "outputs": [],
      "source": "TEXT \u003d Field(tokenize \u003d tokenize_en, \n            fix_length\u003dmax_len,stop_words\u003dstopwords_english,\n            lower \u003d True)\nLABEL \u003d Field(sequential\u003dFalse, use_vocab\u003dFalse)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "outputs": [],
      "source": "train, val, test \u003d TabularDataset.splits(\n        path\u003ddata_path, train\u003d\u0027train.csv\u0027,skip_header\u003dTrue,\n        validation\u003d\u0027val.csv\u0027, test\u003d\u0027test.csv\u0027, format\u003d\u0027csv\u0027,\n        fields\u003d[(\u0027text\u0027, TEXT), (\u0027label\u0027, LABEL)])",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "outputs": [],
      "source": "vector \u003d Vectors(\"glove.6B.100d.txt\", cache\u003dvocab_path)\n# vector.unk_init \u003d init.xavier_uniform\nTEXT.build_vocab(train, vectors\u003dvector)\nweight_matrix \u003d TEXT.vocab.vectors\nweight_matrix \u003d weight_matrix.cuda()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "outputs": [],
      "source": "train_iter, val_iter \u003d BucketIterator.splits(\n        (train, val),\n        batch_sizes\u003d(batch_size, batch_size),\n        device\u003ddevice,\n        sort_key\u003dlambda x: len(x.Text), # the BucketIterator needs to be told what function it should use to group the data.\n        sort_within_batch\u003dFalse    \n)\ntest_iter \u003d Iterator(test, batch_size\u003dbatch_size, device\u003ddevice, sort\u003dFalse, sort_within_batch\u003dFalse, repeat\u003dFalse)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "outputs": [
        {
          "data": {
            "text/plain": "\n[torchtext.data.batch.Batch of size 32]\n\t[.text]:[torch.cuda.LongTensor of size 56x32 (GPU 0)]\n\t[.label]:[torch.cuda.LongTensor of size 32 (GPU 0)]"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 168
        }
      ],
      "source": "batch \u003d next(iter(train_iter))\nbatch",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "outputs": [],
      "source": "class BatchWrapper:\n    def __init__(self, dl, x_var, y_vars):\n        self.dl, self.x_var, self.y_vars \u003d dl, x_var, y_vars # we pass in the list of attributes for x and y\n    \n    def __iter__(self):\n        for batch in self.dl:\n            x \u003d getattr(batch, self.x_var) # we assume only one input in this wrapper\n            \n            if self.y_vars is not None: # we will concatenate y into a single tensor\n                y \u003d t.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y_vars], dim\u003d1).float()\n            else:\n                y \u003d t.zeros((1))\n\n            yield (x, y)\n    \n    def __len__(self):\n        return len(self.dl)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "outputs": [],
      "source": "train_dl \u003d BatchWrapper(train_iter, \"text\", [\"label\"])\nvalid_dl \u003d BatchWrapper(val_iter, \"text\", [\"label\"])\ntest_dl \u003d BatchWrapper(test_iter, \"text\", [\"label\"])\n# next(train_dl.__iter__())",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "outputs": [],
      "source": "class TextCNN(nn.Module):\n    def __init__(self, embeddings, vocab_size, embedding_dim, output_size, \n                 num_filters\u003d100, kernel_sizes\u003dNone , freeze_embeddings\u003dTrue, drop_prob\u003d0.5):\n        if kernel_sizes is None:\n\t        kernel_sizes \u003d [3, 4, 5]\n        super(TextCNN, self).__init__()\n        self.num_filters \u003d num_filters\n        self.embedding_dim \u003d embedding_dim\n        self.embedding \u003d nn.Embedding(vocab_size, embedding_dim)\n        self.embedding.weight \u003d nn.Parameter(embeddings) # all vectors\n        if freeze_embeddings:\n            self.embedding.requires_grad \u003d False\n        self.convs \u003d nn.ModuleList([\n            nn.Conv2d(1, num_filters, (k, embedding_dim), padding\u003dk-2) \n            for k in kernel_sizes])\n        self.fc \u003d nn.Linear(len(kernel_sizes) * num_filters, output_size) \n        self.dropout \u003d nn.Dropout(drop_prob)\n        self.softmax \u003d nn.Softmax()\n        \n    def conv_and_pool(self, x, conv):\n        # squeeze last dim to get size: (batch_size, num_filters, conv_seq_length, 1) -\u003e (batch_size, num_filters, conv_seq_length)\n        x \u003d F.relu(conv(x)).squeeze()\n        # 1D pool over conv_seq_length, squeeze to get size: (batch_size, num_filters)\n        x_max \u003d F.max_pool1d(x, x.size(2)).squeeze(2)\n        return x_max\n\n    def forward(self, x):\n        # (batch_size, seq_length, embedding_dim)\n        embeddings \u003d self.embedding(x) \n        # embeddings.unsqueeze(1) creates a channel dimension that conv layers expect \n        # (batch_size, channel, seq_length, embedding_dim)\n        embeddings \u003d embeddings.unsqueeze(1)\n        conv_results \u003d [self.conv_and_pool(embeddings, conv) for conv in self.convs]\n        # concatenate results \n        x \u003d t.cat(conv_results, 1)\n        x \u003d self.dropout(x)\n        logits \u003d self.fc(x) \n        return self.softmax(logits)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "TextCNN(\n  (embedding): Embedding(15312, 100)\n  (convs): ModuleList(\n    (0): Conv2d(1, 100, kernel_size\u003d(3, 100), stride\u003d(1, 1), padding\u003d(1, 1))\n    (1): Conv2d(1, 100, kernel_size\u003d(4, 100), stride\u003d(1, 1), padding\u003d(2, 2))\n    (2): Conv2d(1, 100, kernel_size\u003d(5, 100), stride\u003d(1, 1), padding\u003d(3, 3))\n  )\n  (fc): Linear(in_features\u003d300, out_features\u003d5, bias\u003dTrue)\n  (dropout): Dropout(p\u003d0.5)\n  (softmax): Softmax()\n)",
            "\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "model \u003d TextCNN(weight_matrix, weight_matrix.size(0), weight_matrix.size(1),classes, num_filters, kernel_sizes)\nprint(model)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "outputs": [],
      "source": "criterion \u003d nn.CrossEntropyLoss()\noptimizer \u003d t.optim.Adam(model.parameters(), lr\u003dlr)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "outputs": [],
      "source": "# training loop\ndef train(model, train_loader, valid_loader, epochs, print_every\u003d100):\n    if use_gpu:\n        model.cuda()\n    counter \u003d 0\n    model.train()\n    for e in range(epochs):\n        # batch loop\n        for inputs, labels in train_loader:\n            counter +\u003d 1\n            if use_gpu:\n                inputs, labels \u003d inputs.cuda(), labels.cuda()\n            model.zero_grad()\n            output \u003d model(inputs)\n            loss \u003d criterion(output.squeeze(), labels.float())\n            loss.backward()\n            optimizer.step()\n            if counter % print_every \u003d\u003d 0:\n                val_losses \u003d []\n                accuracy \u003d []\n                model.eval()\n                for inputs, labels in valid_loader:\n                    if(use_gpu):\n                        inputs, labels \u003d inputs.cuda(), labels.cuda()\n                    output \u003d model(inputs)\n                    val_loss \u003d criterion(output.squeeze(), labels.float())\n                    val_losses.append(val_loss.item())\n                    predict_label \u003d np.argmax(output, axis\u003d0)\n                    accuracy.append(np.sum((predict_label \u003d\u003d labels) / float(batch_size)))\n                model.train()\n                print(\"Epoch\\t{}/{}...\".format(e+1, epochs),\n                      \"Step\\t}...\".format(counter),\n                      \"Loss\\t{:.6f}...\".format(loss.item()),\n                      \"Val_Loss\\t{:.6f}\".format(np.mean(val_losses)),\n                      \"Val_Accuracy\\t{:.6f}...\".format(accuracy))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-137-271dc81cda1e\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[1;32m----\u003e 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name \u0027epochs\u0027 is not defined"
          ],
          "ename": "NameError",
          "evalue": "name \u0027epochs\u0027 is not defined",
          "output_type": "error"
        }
      ],
      "source": "train(model, train_dl, valid_dl, epochs, print_every\u003dprint_every)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-186-44af4c971aa6\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 10\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mpredict_label\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--\u003e 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m\u003cipython-input-178-f1bdd5bb413b\u003e\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# (batch_size, channel, seq_length, embedding_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 33\u001b[1;33m         \u001b[0mconv_results\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_and_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;31m# concatenate results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m\u003cipython-input-178-f1bdd5bb413b\u003e\u001b[0m in \u001b[0;36m\u003clistcomp\u003e\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# (batch_size, channel, seq_length, embedding_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 33\u001b[1;33m         \u001b[0mconv_results\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_and_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;31m# concatenate results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m\u003cipython-input-178-f1bdd5bb413b\u003e\u001b[0m in \u001b[0;36mconv_and_pool\u001b[1;34m(self, x, conv)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# 1D pool over conv_seq_length, squeeze to get size: (batch_size, num_filters)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 24\u001b[1;33m         \u001b[0mx_max\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx_max\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--\u003e 133\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool1d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     return torch.max_pool1d(\n\u001b[1;32m--\u003e 461\u001b[1;33m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m max_pool1d \u003d torch._jit_internal.boolean_dispatch(\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Expected 3-dimensional tensor, but got 4-dimensional tensor for argument #1 \u0027self\u0027 (while checking arguments for max_pool1d)"
          ],
          "ename": "RuntimeError",
          "evalue": "Expected 3-dimensional tensor, but got 4-dimensional tensor for argument #1 \u0027self\u0027 (while checking arguments for max_pool1d)",
          "output_type": "error"
        }
      ],
      "source": "test_losses \u003d [] # track loss\nnum_correct \u003d 0\nmodel.eval()\n# iterate over test data\nres \u003d np.empty([len(test_dl.dl.dataset), 2])\nfor inputs, labels in test_dl:\n    if(use_gpu):\n        model.cuda()\n        inputs, labels \u003d inputs.cuda(), labels.cuda()\n    output \u003d model(inputs)\n    predict_label \u003d np.argmax(output, axis\u003d0)\n    t.cat([labels, predict_label], 0)\n    break\n# test_losses \u003d [] # track loss\n# num_correct \u003d 0\n# model.eval()\n# # iterate over test data\n# for inputs, labels in test_dl:\n# \n#     if(use_gpu):\n#         inputs, labels \u003d inputs.cuda(), labels.cuda()\n#     output \u003d model(inputs)\n#     test_loss \u003d criterion(output.squeeze(), labels.float())\n#     test_losses.append(test_loss.item())\n#     predict_label \u003d np.argmax(output, axis\u003d0)\n#     # compare predictions to true label\n#     correct \u003d np.sum(predict_label \u003d\u003d labels)\n#     num_correct +\u003d correct\n# \n# print(\"Test loss\\t{:.6f}\".format(np.mean(test_losses)))\n# test_acc \u003d num_correct/len(test_dl.dl.dataset)\n# print(\"Test accuracy\\t{:.3f}\".format(test_acc))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "conda-root-py",
      "language": "python",
      "display_name": "Python [conda env:root] *"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}